{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "results = pd.DataFrame(columns = ['model', 'task', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Разделите выборку на обучающую и тестовую в отношении 70%/30%, предварительно выделив целевую переменную (колонка 'quality')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1119, 11), (480, 11), (1119,), (480,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# выделим целевую переменную y\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Оцените качество на тестовой выборке по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.554167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>task2</td>\n",
       "      <td>0.654167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model   task  accuracy\n",
       "0  DecisionTreeClassifier  task2  0.554167\n",
       "1      BaggingClassifier   task2  0.641667\n",
       "2  RandomForestClassifier  task2  0.654167"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#обучаем модель DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "#оцениваем качество на тестовой выборке\n",
    "y_pred = dtc.predict(X_test)\n",
    "acc_DT = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#обучаем модель BaggingClassifier, n_estimators=количество деревьев\n",
    "bc = BaggingClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "#оцениваем качество на тестовой выборке\n",
    "y_pred = bc.predict(X_test)\n",
    "acc_Bagging = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#обучаем модель RandomForestClassifier \n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "#оцениваем качество на тестовой выборке\n",
    "y_pred = rfc.predict(X_test)\n",
    "acc_RF = accuracy_score(y_test, y_pred)\n",
    "\n",
    "results.loc[0] = ['DecisionTreeClassifier', 'task2', acc_DT]\n",
    "results.loc[1] = ['BaggingClassifier ', 'task2', acc_Bagging]\n",
    "results.loc[2] = ['RandomForestClassifier', 'task2', acc_RF]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BaggingClassifier и RandomForestClassifier показывают более точные результаты, так как они являются ансамблевыми методами, которые объединяют прогнозы нескольких базовых оценок. Также в модели используется достаточное количество деревьев, чтобы точность превышала точность при использовании DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1119, 11), (480, 11), (1119,), (480,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# выделим целевую переменную y\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#значения деревьев:\n",
    "trees_count = [10, 50, 100]\n",
    "trees_count.extend([i for i in range(200, 5001, 200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "\n",
    "# для каждой выборки деревьев находим оценку \n",
    "for temp_trees_count in trees_count:\n",
    "    \n",
    "    # обучаем модель на тренировочной выборке\n",
    "    model = RandomForestClassifier(n_estimators=temp_trees_count, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #оцениваем качество на тестовой выборке\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Постройте график зависимости качества от числа деревьев.\n",
    "plt.plot(trees_count, accuracy_list)\n",
    "plt.xlabel('Количество деревьев')\n",
    "plt.ylabel('Качество (Accuracy)')\n",
    "plt.title('Зависимость качества от числа деревьев')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#мpip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# выделим целевую переменную y\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "acc_sklearn = cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "# XGBClassifier\n",
    "clf = xgb.XGBClassifier(random_state=RANDOM_STATE)\n",
    "le = LabelEncoder()#исправляем ошибку нумерации после применения XGBClassifier\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "acc_xgboost = cross_val_score(clf, X, y, cv=5, scoring='accuracy', error_score='raise').mean()\n",
    "acc_RF = accuracy_score(y_test, y_pred)\n",
    "\n",
    "results.loc[3] = ['GradientBoostingClassifier', 'task4', acc_sklearn]\n",
    "results.loc[4] = ['XGBClassifier', 'task4', acc_xgboost]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# выделим целевую переменную y\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall xgboost \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install xgboost==0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем параметры для оптимизации:\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# sklearn GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "best_params = grid.best_params_\n",
    "print('Лучшие параметры sklearn:\\n', best_params)\n",
    "\n",
    "acc_sklearn_cv = grid.score(X_test, y_test)\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# xgboost XGBClassifier\n",
    "clf = xgb.XGBClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "#le = LabelEncoder()#исправляем ошибку нумерации после применения XGBClassifier\n",
    "#y = le.fit_transform(y)\n",
    "#y_train = le.fit_transform(y_train)\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "best_params = grid.best_params_\n",
    "print('Лучшие параметрыx gboost:\\n', best_params)\n",
    "\n",
    "acc_xgboost_cv = grid.score(X_test, y_test)\n",
    "\n",
    "results.loc[5] = ['GradientBoostingClassifier_CV', 'task5', acc_sklearn_cv]\n",
    "results.loc[6] = ['XGBClassifier_CV', 'task5', acc_xgboost_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[5]\n",
    "results.loc[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# X - матрица признаков, y - целевая переменная\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier()\n",
    "acc_lightgbm = cross_val_score(clf, X, y, cv=5).mean()\n",
    "\n",
    "clf = CatBoostClassifier(verbose=0)\n",
    "acc_catboost = cross_val_score(clf, X, y, cv=5).mean()\n",
    "\n",
    "results.loc[7] = ['LGBMClassifier', 'task6', acc_lightgbm]\n",
    "results.loc[8] = ['CatBoostClassifier', 'task6', acc_catboost]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями.\n",
    "Сравните значение метрики accuracy. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "#!pip install lightgbm\n",
    "#!pip install catboost\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# X - матрица признаков, y - целевая переменная\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определить параметры для оптимизации и диапазоны их значений\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "# определение модели градиентного бустинга lightgbm\n",
    "lgb_model = LGBMClassifier()\n",
    "lgb_gs = GridSearchCV(lgb_model, param_grid, cv=3)\n",
    "lgb_gs.fit(X_train, y_train)\n",
    "best_params_lightgbm = lgb_gs.best_params_\n",
    "\n",
    "\n",
    "# создание моделей с лучшими параметрами и получение метрики accuracy на тестовой выборке\n",
    "lgb_best_model = LGBMClassifier(**best_params_lightgbm)\n",
    "lgb_best_model.fit(X_train, y_train)\n",
    "lgb_pred = lgb_best_model.predict(X_test)\n",
    "acc_lightgbm_cv = accuracy_score(y_test, lgb_pred)\n",
    "\n",
    "print('Параметры лучшей модели lightgbm:\\n', best_params_lightgbm)\n",
    "results.loc[9] = ['LGBMClassifier_CV', 'task7', acc_lightgbm_cv]\n",
    "results.loc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определение модели градиентного бустинга catboost\n",
    "cat_model = CatBoostClassifier()\n",
    "cat_gs = GridSearchCV(cat_model, param_grid, cv=3)\n",
    "cat_gs.fit(X_train, y_train)\n",
    "best_params_catboost = cat_gs.best_params_\n",
    "\n",
    "# создание моделей с лучшими параметрами и получение метрики accuracy на тестовой выборке\n",
    "cat_best_model = CatBoostClassifier(**best_params_catboost)\n",
    "cat_best_model.fit(X_train, y_train)\n",
    "cat_pred = cat_best_model.predict(X_test)\n",
    "acc_catboost_cv = accuracy_score(y_test, cat_pred)\n",
    "\n",
    "print('Параметры лучшей модели catboost:\\n', best_params_catboost)\n",
    "\n",
    "results.loc[10] = ['CatBoostClassifier_CV', 'task7', acc_catboost_cv]\n",
    "results.loc[10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [optuna](https://github.com/optuna/optuna) . Параметры для оптимизации:\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#!pip install optuna\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# X - матрица признаков, y - целевая переменная\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "def objective(trial):\n",
    "    # Определяем диапазоны для параметров, которые будут оптимизироваться\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 9)\n",
    "    \n",
    "    # Создаем классификатор с заданными параметрами\n",
    "    clf = XGBClassifier(learning_rate=learning_rate, n_estimators=n_estimators, max_depth=max_depth)\n",
    "    # Вычисляем значение метрики accuracy по кросс-валидации\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=3, scoring='accuracy')\n",
    "    # Возвращаем среднее значение метрики по всем фолдам\n",
    "    return score.mean()\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params_xgboost_optuna = study.best_trial\n",
    "acc_xgboost_optuna = best_params_xgboost_optuna.value\n",
    "\n",
    "print('Параметры лучшей модели xgboost:\\n', best_params_xgboost_optuna)\n",
    "\n",
    "results.loc[11] = ['XGBClassifier_optuna', 'task8', acc_xgboost_optuna]\n",
    "results.loc[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# X - матрица признаков, y - целевая переменная\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим модели 4-х алгоритмов с базовыми параметрами градиентного бустинга\n",
    "gbm = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "xgb = XGBClassifier(random_state=RANDOM_STATE)\n",
    "lgbm = LGBMClassifier(random_state=RANDOM_STATE)\n",
    "cat = CatBoostClassifier(random_state=RANDOM_STATE, verbose=False)\n",
    "\n",
    "# созданеие стекинга\n",
    "estimators = [('gbm', gbm), ('xgb', xgb), ('lgbm', lgbm), ('cat', cat)]\n",
    "clf  = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "#обучаем модель\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc_stacking_default = accuracy_score(y_test, y_pred)\n",
    "\n",
    "results.loc[12] = ['Stacking default', 'task9', acc_stacking_default]\n",
    "results.loc[12] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "\n",
    "# X - матрица признаков, y - целевая переменная\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# создадим модели 4-х алгоритмов с базовыми параметрами градиентного бустинга\n",
    "gb = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "xgb = XGBClassifier(random_state=RANDOM_STATE)\n",
    "lgbm = LGBMClassifier(random_state=RANDOM_STATE)\n",
    "cat = CatBoostClassifier(random_state=RANDOM_STATE, verbose=0)\n",
    "\n",
    "# созданеие стекинга\n",
    "estimators = [('gb', gb), ('xgb', xgb), ('lgbm', lgbm), ('cat', cat)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "\n",
    "# параметры для оптимизации и диапазоны их значений\n",
    "\n",
    "param_grid = {\n",
    "    'gb__learning_rate': [0.01, 0.1, 1],\n",
    "    'gb__n_estimators': [50, 100, 200],\n",
    "    'gb__max_depth': [3, 5, 7],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 1],\n",
    "    'xgb__n_estimators': [50, 100, 200],\n",
    "    'xgb__max_depth': [3, 5, 7],\n",
    "    'lgbm__learning_rate': [0.01, 0.1, 1],\n",
    "    'lgbm__n_estimators': [50, 100, 200],\n",
    "    'lgbm__max_depth': [3, 5, 7],\n",
    "    'cat__learning_rate': [0.01, 0.1, 1],\n",
    "    'cat__n_estimators': [50, 100, 200],\n",
    "    'cat__max_depth': [3, 5, 7]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# обучаем модель\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#модельс оптимальными параметрами\n",
    "best_params = grid_search.best_estimator_\n",
    "\n",
    "best_params.fit(X_train, y_train)\n",
    "y_pred = best_params.predict(X_test)\n",
    "\n",
    "acc_stacking = accuracy_score(y_test, y_pred)\n",
    "\n",
    "results.loc[13] = ['Stacking', 'task10', acc_stacking]\n",
    "results.loc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
